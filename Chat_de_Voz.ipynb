{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mxrkxzzz/Basic-Chatbot/blob/main/Chat_de_Voz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkuCT2Uo5TSu"
      },
      "outputs": [],
      "source": [
        "## Librería transformers para manejar datos como el LPN.\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3EuEMDV5rWi"
      },
      "outputs": [],
      "source": [
        "## librerías colab_utils y librosa, permite cargar y visualizar archivos de audio dentro de su propia aplicación\n",
        "!pip install git+https://github.com/ricardodeazambuja/colab_utils.git\n",
        "!pip install librosa==0.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nuRVIkx7DsM"
      },
      "outputs": [],
      "source": [
        "## librerías para el procesamiento del audio\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from colab_utils import getAudio\n",
        "import librosa\n",
        "## librería para creación de vectores y matrices.\n",
        "import numpy as np\n",
        "## pytorch para la conversión de voz a texto\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzElTekK7NWr"
      },
      "outputs": [],
      "source": [
        "w2v2_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "w2v2 = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZK_5f3U7XKL"
      },
      "outputs": [],
      "source": [
        "## método getAudio de la librería colab_utils.. para capturar el audio desde nuestro micrófono.\n",
        "audio, sr = getAudio()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T93FX50O7y6s"
      },
      "outputs": [],
      "source": [
        "# Representar cada muestra en formato punto flotante con 32 bits\n",
        "audio_float = audio.astype(np.float32)\n",
        "\n",
        "# Y cambiar la frecuencia de muestreo a 16 KHz\n",
        "audio_16k = librosa.resample(audio_float, sr, 16000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVJbspZV_Qz1"
      },
      "outputs": [],
      "source": [
        "# conversión de voz a texto\n",
        "entrada = w2v2_processor(audio_16k, sampling_rate=16000, return_tensors=\"pt\").input_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0-5o4OkAQfV"
      },
      "outputs": [],
      "source": [
        "## arreglo de 203 x 32\n",
        "probabilidades = w2v2(entrada).logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHXDhahmATEJ"
      },
      "outputs": [],
      "source": [
        "predicciones = torch.argmax(probabilidades, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vk0CMDAKAWCe"
      },
      "outputs": [],
      "source": [
        "## pasa de una representación numérica a una secuencia de caracteres.\n",
        "transcripcion = w2v2_processor.decode(predicciones[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqgQVXa5AfCU"
      },
      "outputs": [],
      "source": [
        "## librería que se utiliza para procesar el texto a un formato que sea entendible para el modelo.\n",
        "## tokenizador separará el texto en palabras llamadas tokens\n",
        "## tokens, consiste en la segmentación del texto en frases o palabras\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/blenderbot-400M-distill\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_TDRn2SAglj"
      },
      "outputs": [],
      "source": [
        "entradaBlender = tokenizer([transcripcion], return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxkqHBndAraG"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "blender = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/blenderbot-400M-distill\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scpEAMtdA77D"
      },
      "outputs": [],
      "source": [
        "ids_respuesta = blender.generate(**entradaBlender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBGwPuZwBATM"
      },
      "outputs": [],
      "source": [
        "## tensor, ## Son una generalización de vectores y matrices y se entienden fácilmente como una matriz multidimensional\n",
        "print(ids_respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2zkuZdrBFbp"
      },
      "outputs": [],
      "source": [
        "respuesta = tokenizer.batch_decode(ids_respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpKvNFdPBIb-"
      },
      "outputs": [],
      "source": [
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZMQ1L8jBOxG"
      },
      "outputs": [],
      "source": [
        "respuesta = respuesta[0].replace('<s>','').replace('</s>','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "exfxFSJSBUbV"
      },
      "outputs": [],
      "source": [
        "NFRASES = 6\n",
        "nfrase = 1\n",
        "\n",
        "while nfrase <= NFRASES:\n",
        "  input()     # Esperar a pulsar tecla para iniciar grabación\n",
        "\n",
        "  # Capturar audio y llevarlo a 16 KHz\n",
        "  audio, sr = getAudio()\n",
        "  audio_float = audio.astype(np.float32)\n",
        "  audio_16k = librosa.resample(audio_float, sr, 16000)\n",
        "\n",
        "  # Voz a texto con wav2vec2\n",
        "  entrada = w2v2_processor(audio_16k, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "  probabilidades = w2v2(entrada).logits\n",
        "  predicciones = torch.argmax(probabilidades, dim=-1)\n",
        "  frase = w2v2_processor.decode(predicciones[0])\n",
        "\n",
        "  # Imprimir transcripción voz a texto\n",
        "  print(f'-> MIGUEL: {frase}')\n",
        "\n",
        "  # BlenderBot\n",
        "  entradaBlender = tokenizer([frase], return_tensors='pt')\n",
        "  ids_respuesta = blender.generate(**entradaBlender)\n",
        "  respuesta = tokenizer.batch_decode(ids_respuesta)\n",
        "  respuesta = respuesta[0].replace('<s>','').replace('</s>','')\n",
        "  print(f'-> BLENDERBOT: {respuesta}')\n",
        "\n",
        "  nfrase += 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}